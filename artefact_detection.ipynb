{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VT15o2m_rTqb"
   },
   "source": [
    "### **Object detection for artefacts in documents**\n",
    "\n",
    "In this notebook, we will explore how to use a popular object detection architecture, [Faster-RCNN](https://arxiv.org/abs/1506.01497), to detect QR codes, bar codes, logos and ID pictures in documents.\n",
    "\n",
    "Faster R-CNN is an end-to-end architecture, which leverages a dedicated module to generate region proposals (considerably more efficient than traditional algorithms like Selective Search). The features of those localization candidates are then extracted by an ROI Pooling layer to produce fixed-size feature maps from each candidate. The network can accurately and quickly predict the locations of different objects. Please refer to [Faster R-CNN Explained for Object Detection Tasks](https://blog.paperspace.com/faster-r-cnn-explained-object-detection/) for a quick introduction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYVSYfRLKNGt"
   },
   "source": [
    "## Setup\n",
    "Installing requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Zpz2jSfZRJmf",
    "outputId": "9564809e-13a7-486d-f3cb-0350115d007f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"sudo\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycairo\n",
      "  Obtaining dependency information for pycairo from https://files.pythonhosted.org/packages/84/a8/79aab9217cf08817fbc425a5a36f67837cbc877456546b658db7ae7d9dc8/pycairo-1.26.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading pycairo-1.26.0-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Downloading pycairo-1.26.0-cp310-cp310-win_amd64.whl (859 kB)\n",
      "   ---------------------------------------- 859.1/859.1 kB 6.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pycairo\n",
      "Successfully installed pycairo-1.26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\maria\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\maria\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\maria\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\maria\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: C:\\Users\\Maria\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Colab related installations to install pyproject.toml projects correctly\n",
    "!sudo apt install libcairo2-dev pkg-config\n",
    "!pip3 install pycairo\n",
    "# Install doctr\n",
    "!pip3 install python-doctr[torch]@git+https://github.com/mindee/doctr.git\n",
    "# Restart runtime\n",
    "exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrvbWXuipRS-"
   },
   "source": [
    "## Inference utilities\n",
    "Import all dependencies at once "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQLo6n0jxyVf",
    "outputId": "b43cc1b2-59d1-403b-c7b9-1e727e2929e1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['USE_TORCH'] = '1'\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import torch\n",
    "\n",
    "from doctr.io.image import read_img_as_tensor\n",
    "from doctr.models import obj_detection\n",
    "\n",
    "# Path to input image file\n",
    "!wget https://images.sampletemplates.com/wp-content/uploads/2018/04/Car-Parking-Receipt-Template.jpg\n",
    "\n",
    "# Detected classes\n",
    "CLASSES = [\"__background__\", \"QR Code\", \"Barcode\", \"Logo\", \"Photo\"]\n",
    "# Color map for each class\n",
    "CM = [(255, 255, 255), (0, 0, 150), (0, 0, 0), (0, 150, 0), (150, 0, 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjcOig6XpT47"
   },
   "source": [
    "Everything you need to plot your model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mbIOoJ29RPC1"
   },
   "outputs": [],
   "source": [
    "# Plots the predictions on the input image\n",
    "def plot_predictions(image, boxes, labels):\n",
    "    for box, label in zip(boxes, labels):\n",
    "        # Bounding box around artefacts\n",
    "        cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]),\n",
    "                      CM[label], 2)\n",
    "        text_size, _ = cv2.getTextSize(CLASSES[label], cv2.FONT_HERSHEY_SIMPLEX, 2, 2)\n",
    "        text_w, text_h = text_size\n",
    "        # Filled rectangle above bounding box\n",
    "        cv2.rectangle(image, (box[0], box[1]), (box[0] + text_w, box[1] - text_h),\n",
    "                      CM[label], -1)\n",
    "        # Text bearing the name of the artefact detected\n",
    "        cv2.putText(image, CLASSES[label], (int(box[0]), int(box[1])),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "    figure(figsize=(10, 8), dpi=90)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9q8gcz0qpbX"
   },
   "source": [
    "## Visualizing your detections\n",
    "`img_path: str` >> path to image file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "LZ83ebGCSQWK",
    "outputId": "7f99b629-8a8f-41b7-c4ba-a0856825beb0"
   },
   "outputs": [],
   "source": [
    "# Initializing the model fasterrcnn_mobilenet_v3_large_fpn\n",
    "model = obj_detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True, num_classes=5).eval()\n",
    "\n",
    "img_path = \"Car-Parking-Receipt-Template.jpg\"\n",
    "# Reading the input image\n",
    "img = read_img_as_tensor(img_path).unsqueeze(0)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    img = img.cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(img)\n",
    "\n",
    "labels = pred[0]['labels'].detach().cpu().numpy()\n",
    "labels = labels.round().astype(int)\n",
    "boxes = pred[0]['boxes'].detach().cpu().numpy()\n",
    "boxes = boxes.round().astype(int)\n",
    "img = (255 * img.cpu().squeeze(0).permute(1, 2, 0).numpy().copy()).round().astype(np.uint8)\n",
    "plot_predictions(img, boxes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "artefact_detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
